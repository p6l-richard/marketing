# Firecrawl Rate Limiting Fix - Comprehensive Solution

## Problem Summary

The keyword research workflow was encountering rate limiting errors (HTTP 429) when making concurrent requests to Firecrawl API, causing the entire workflow to fail. The specific issues were:

1. **Concurrent Requests**: Making 3 simultaneous requests via `Promise.all()` triggered rate limits
2. **No Rate Limit Handling**: No specific retry logic for 429 status codes
3. **Database Field Error**: Typo in database update field (`updatedAtM` instead of `updatedAt`)
4. **Workflow Fragility**: Complete failure when any Firecrawl request failed
5. **Poor Error Handling**: Generic error handling without rate limit specific logic

## Solution Overview

### 1. Enhanced Firecrawl Library (`/workspace/apps/generator /src/lib/firecrawl.ts`)

#### New Features Added:

**A. Rate Limit Detection**
```typescript
function isRateLimitError(error: any): boolean {
  return error?.statusCode === 429 || 
         (error?.message && error.message.includes('429')) ||
         (error?.status === 429);
}
```

**B. Exponential Backoff Retry Logic**
```typescript
async function retryWithExponentialBackoff<T>(
  fn: () => Promise<T>,
  maxRetries: number = 3,
  baseDelay: number = 1000
): Promise<T>
```

- **Smart Retry**: Only retries on rate limit errors (429), not other errors
- **Exponential Backoff**: Delay increases exponentially: 2s, 4s, 8s
- **Jitter**: Random component to prevent thundering herd
- **Max Attempts**: Configurable retry limit (default: 3 attempts)

**C. Sequential Processing Function**
```typescript
export async function getOrCreateFirecrawlResponsesSequentially(
  requests: Array<{ url: string; connectTo: { term: string } }>,
  delayBetweenRequests: number = 1000
): Promise<Array<...>>
```

- **Sequential Processing**: Processes URLs one at a time
- **Configurable Delays**: Customizable delay between requests
- **Progress Logging**: Detailed logging of processing status
- **Statistics**: Returns success/failure counts

#### Enhanced Error Handling:

**Before:**
```typescript
catch (error) {
  console.error(`Error processing URL ${args.url}:`, error);
  // Generic error handling - workflow fails
}
```

**After:**
```typescript
catch (error) {
  const errorMessage = error instanceof Error ? error.message : String(error);
  const isRateLimit = isRateLimitError(error);
  
  console.error(`${isRateLimit ? 'Rate limit' : 'Error'} processing URL ${args.url}:`, error);
  
  // Store error and continue - workflow resilient to partial failures
  return await db.query.firecrawlResponses.findFirst({
    where: eq(firecrawlResponses.sourceUrl, args.url),
  });
}
```

#### Database Fixes:
- Fixed typo: `updatedAtM` â†’ `updatedAt`
- Proper timestamp handling with `new Date()` instead of `Date.now()`
- Added missing `inputTerm` field in error cases

### 2. Updated Keyword Research Task (`/workspace/apps/generator /src/trigger/glossary/keyword-research.ts`)

#### Key Changes:

**Before - Concurrent Processing:**
```typescript
const firecrawlResults = await Promise.all(
  topThree.map((result) =>
    getOrCreateFirecrawlResponse({ url: result.link, connectTo: { term: term } }),
  ),
);
```

**After - Sequential Processing:**
```typescript
const firecrawlResults = await getOrCreateFirecrawlResponsesSequentially(
  topThree.map((result) => ({
    url: result.link,
    connectTo: { term: term }
  })),
  1500 // 1.5 second delay between requests
);
```

#### Enhanced Monitoring:
- **Success/Failure Tracking**: Separates successful vs failed scraping attempts
- **Detailed Logging**: Reports exactly which URLs failed and why
- **Statistics**: Returns comprehensive stats about scraping results
- **Graceful Degradation**: Continues processing even if some URLs fail

## Benefits of the Solution

### 1. Rate Limiting Protection
- **Exponential Backoff**: Automatically handles temporary rate limits
- **Sequential Processing**: Prevents overwhelming the API
- **Configurable Delays**: Can be tuned based on API limits

### 2. Improved Reliability
- **Partial Failure Resilience**: Workflow continues even if some URLs fail
- **Smart Retry Logic**: Only retries appropriate errors
- **Better Error Context**: Clear distinction between rate limits and other errors

### 3. Enhanced Monitoring
- **Detailed Statistics**: Track success/failure rates
- **Progress Visibility**: See exactly which URLs are being processed
- **Comprehensive Logging**: Better debugging and monitoring

### 4. Maintainability
- **Type Safety**: Proper TypeScript types for Firecrawl responses
- **Separation of Concerns**: Rate limiting logic isolated from business logic
- **Reusable Functions**: Sequential processing can be used elsewhere

## Configuration Options

### Rate Limiting Parameters:
- **Max Retries**: Default 3, configurable per call
- **Base Delay**: Default 2000ms (2 seconds)
- **Request Delay**: Default 1500ms between sequential requests

### Usage Examples:

**Basic Usage:**
```typescript
const result = await getOrCreateFirecrawlResponse({
  url: "https://example.com",
  connectTo: { term: "api" }
});
```

**Sequential Processing:**
```typescript
const results = await getOrCreateFirecrawlResponsesSequentially([
  { url: "https://example1.com", connectTo: { term: "api" } },
  { url: "https://example2.com", connectTo: { term: "api" } },
], 2000); // 2 second delay between requests
```

## Testing Recommendations

1. **Rate Limit Testing**: Test with a high volume of requests to verify rate limiting works
2. **Failure Scenarios**: Test partial failures to ensure workflow resilience
3. **Performance Testing**: Measure the impact of sequential vs concurrent processing
4. **Monitoring**: Verify that statistics and logging provide adequate visibility

## Future Improvements

1. **Dynamic Rate Limiting**: Adjust delays based on API response headers
2. **Circuit Breaker**: Temporarily stop requests if too many failures occur
3. **Parallel Processing with Limits**: Use a semaphore to limit concurrent requests
4. **Metric Collection**: Add metrics for monitoring rate limit frequency

## Migration Impact

- **Backward Compatible**: Existing code continues to work
- **Performance**: Sequential processing is slower but more reliable
- **Resource Usage**: Lower peak load on Firecrawl API
- **Cost**: Potentially lower API costs due to fewer failed requests

This solution transforms the keyword research workflow from fragile and prone to rate limiting failures into a robust, resilient system that gracefully handles API limitations while providing comprehensive monitoring and statistics.